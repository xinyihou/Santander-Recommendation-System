### ./logistic-regression/logistic_regression.r ###date()lambda = 0.1# X.rda has 12669961 rows# Original training has 13619575 rowstrain <- function (X, Y, lambda) {  MSE_THRESHOLD = 0.000001  Y = as.numeric(Y)  m = length(Y) # numer of samples 12669961  n = 1 + length(X) # number of features, including bias  w = rep(0, n)  epocherrors = rep(0, m)  prevmserrs = rep(0, 4)  for (epoch in 1:20) {    order = sample.int(m, m)    for (row in order) {      x = c(1, as.numeric(X[row,]))      y = Y[row]      err0 = y - 1/(1 + exp(w %*% x)) + lambda * w %*% w      gra = err0 * x      a = 0.1      sqerr0 = err0^2      if (sqerr0 < MSE_THRESHOLD) {        epocherrors[row] <- sqerr0        next      }            # Search for a that yields error less than 'err'      for (i in 1:64) {        w1 = w + a * gra        err1 = y - 1/(1 + exp(w1 %*% x)) + lambda * w1 %*% w1        sqerr1 = err1^2        if (sqerr1 <= sqerr0) {          w = w1          break        }        a = a / 2      }      if (100 == i) warning(sprintf('i == 100; didn\'t get good error. epoch %d\t%f vs %f', epoch, err1, err))      # Save error for calculating mse across samples      epocherrors[row] <- sqerr1      if (any(is.na(epocherrors))) {        stop('na err')      }    } # end of epoch    # Calc current error    mserr = epocherrors[row] / m    print(sprintf('epoch %3d    error %f', epoch, mserr))    # Check satisfaction conditions    if (mserr < MSE_THRESHOLD)      return(w)    if (epoch > length(prevmserrs) && all(round(prevmserrs, 7) == round(mserr, 7)))      return(w)    prevmserrs[1 + epoch %% length(prevmserrs)] = mserr    if (epoch > 4)      print(prevmserrs)  }  warning(sprintf('performed max epochs (%d) on regression', epoch))  return (w)}test <- function (X, Y, w) {  X     = data.matrix(X)  X     = cbind(rep(1, nrow(X)), X)  h     = 1/(1 + exp( X %*% w ))  errs  = h - Y  mserr = mean(errs^2)  print(sprintf('testing mean squared error %f', mserr))  return(mserr)}# Routineargs = commandArgs(trailingOnly=TRUE)REGRESSION_INDEX <- as.numeric(args[1])print(sprintf('REGRESSION INDEX %d', REGRESSION_INDEX))file_suffix <- args[2]load(sprintf('Y%s.rda', file_suffix))if (!exists('Y')) Y = subYprint(sprintf('number of rows: %d', nrow(Y)))load(sprintf('X%s.rda', file_suffix))if (!exists('X')) X = subXX[is.na(X)] <- 0X <- X[,-c(1,2)] # omit D.nomcodpers & fecha_dato Y <- Y[,-c(1,2)] # omit D.nomcodpers & fecha_datoY = Y[, REGRESSION_INDEX]sampleCt = length(Y)testRows = sample.int(sampleCt, sampleCt*.1)# Trainw = train(X[-testRows,], Y[-testRows], lambda)print('WEIGHTS')print(w)save(w, file=sprintf('w-%d-%08d.rda', REGRESSION_INDEX, sampleCt))print(sprintf('REGRESSION INDEX %d', REGRESSION_INDEX))# Testmserr = test(X[testRows,], Y[testRows], w)# Cleanupprint(sprintf('LOGREG SUMMARY : %d : %s : %d : %10f', REGRESSION_INDEX, names(Y)[REGRESSION_INDEX], sampleCt, mserr))print(warnings())date()### ./logistic-regression/gradient_descent.r ###THRESHOLD = 0.000001mse <- function(x, y, w, a, g, lambda) {	# Calc new weights	w = w - a * g	# Calc new error	err = (y - (x %*% w))^2 + lambda * w %*% w	# Return	return(err[[1]])}find_right_bound <- function(x, y, w, errL, g, lambda) {	a = 1	count = 0	repeat {		count = count + 1		print(sprintf('count %d\ta %f\n', count, a))		errR = mse(x, y, w, a, g, lambda)		print(errR)		print(errL)		if (errR > errL) {			return(list(a, errR))		}		if (Inf == a) {			warning('Reached infinite learning rate in looking for right bound for steepest descent')			break		}		a = a * 2	}}# Use SGD + L2-norm regularization + steepest descent# Assumes use of X.rda and Y.rdagradient_descent <- function (X, Y, lambda) {	X = X[,-c(1,2)] # omit D.ncodpers and fecha_dato	Y = Y[,-c(1,2)] # omit D.ncodpers and fecha_dato	w = rep(0, 1+length(X))	m = length(Y)	for (i in 1:length(Y)) {		print(i)		# Pick random sample		# row = sample.int(nrow(X), 1)		row = i		x = c(1, as.numeric(X[row,]))		y = as.numeric(Y[row])		# kludge - REPLACE THIS		x[is.na(x)] <- 0		# Calc current error		aL = 0		errL = ((y - (x %*% w))^2)[[1]]		if (0 == errL) next;		print('nonzero error')		# Calc gradient		g = x * errL + lambda * w		# Make binary leaps to find right bound for minimum error		rightBound = find_right_bound(x, y, w, errL, g, lambda)		aR = rightBound[[1]]		errR = rightBound[[2]]		# Binary search for steepest descent		for (j in 1:10000) {			aM = mean(c(aL, aR))			errM = mse(x, y, w, aM, g, lambda)[[1]]			print(sprintf('j %d\n',j))			if (errM < THRESHOLD)			if (errL < errR) {				errR = errM				aR = aM			} else {				errL = errM				aL = aM			}			if (abs(aL - aR) < 0.0001 && errL < 0.00001) {				w = w - a * g				break			}		}		if (10000 == j)			warning(sprintf('Reached end of iterations for a steepest descent (after %d samples). Error is %f %f %f', i, errL, errM, errR))	}	return(w)}### ./splitting/step1.r ###to_date <- function (num) {	EPOCH = '1970-01-01';	return(as.POSIXct(num, EPOCH));}if (!exists('D', mode='list'))	D <- read.csv('train.csv');# Get customer ids & reverse indexcids = unique(D$ncodpers); # length is       956645 inv_cids = vector(mode='numeric'); # max is 1553689for (i in 1:length(cids)) {	cid = cids[i];	inv_cids[cid] = i;}print('defined cids and inv_cids');# Vector of dates, where index corresponds to index of cidsmonths = vector(mode='list');# How many CONTIGUOUS months does a each customer have?counts = rep(0, length(cids));# Iterate train.csv entriesfor (i in 1:nrow(D)) {	cid = D$ncodpers[i];	mo  = to_date(D$fecha_dato[i]);	idx = inv_cids[cid];	if (is.na(idx)) stop('no index for cid in inv_cids: ', cid);	if (length(months) < idx || is.null(months[[idx]]))                months[[idx]] = vector(mode='numeric');        months[[idx]] = append(mo, months[[idx]]);	if (0 == i %% 10000) cat(sprintf('\titerated D row %d\n', i));}print('populated "months"');save.image('Split.RData');if (length(months) != length(cids))	stop('mismatch len months vs cids: ', length(months), ':', length(cids));if (sum(is.na(months)))	stop('NA in months');if (sum(is.na(cids)))	stop('NA in cids');# Count contiguous months for each customerfor (row_i in 1:length(months)) {	pairs_ct = 0;	mos = sort(months[[row_i]]);	# Ensure there are no gaps in months	if (length(mos) > 1) {		for (i in 2:length(mos)) {			delta = to_date(mos[i]) - to_date(mos[i-1]);			if (abs(30 - delta) <= 3)				pairs_ct = pairs_ct + 1;		}	}	counts[row_i] = pairs_ct;}save.image('Split.RData');df = data.frame(cids, counts);save.image('Split.RData');### ./splitting/step2.r #### This script does not take more than a few seconds to run.# Feel free to change TEST_RATIO if you want a different number# of test samples.## This script takes X% of each bin (1-16) to be in the testSet.# The bins are numbered 1-16. The number indicates how many ordered# pairs of months exist for the customer in the bin.## For example, in bin 1, all of the customers have only 2 adjacent # months of data (i.e. one ordered pair). That means that exactly# one month of data can be used to predict exactly one (following)# month of data.## If a customer has X ordered pairs, that does not mean that the customer# has X+1 months in a row. For example a customer in bin 2 may have data# for January, February, June, July; that's 4 months, but there are only# 2 opportunities to learn or make predictions.load('Step1.RData')bins = vector(mode='list')testSet = vector(mode='numeric')trainSet = vector(mode='numeric')TEST_RATIO = 0.3for (i in 1:16) {	bins[[i]] = df[df$counts == i,]	# random sample	n = nrow(bins[[i]])	test_n = round( n * TEST_RATIO )	test_indices = sample.int(n, test_n)	# update testSet, trainSet		testSet = append( bins[[i]][test_indices,]$cids, testSet )	trainSet = append( bins[[i]][-(test_indices),]$cids, trainSet )}save.image('Step2.RData')print('testSet is a vector of customer ids')print('trainSet is a vector of customer ids')### ./constants.r ###COLS_0 = c(	'fecha_dato',	'ncodpers',	'ind_empleado',	'pais_residencia',	'sexo',	'age',	'fecha_alta',	'ind_nuevo',	'antiguedad',	'indrel',	'ult_fec_cli_1t',	'indrel_1mes',	'tiprel_1mes',	'indresi',	'indext',	'conyuemp',	'canal_entrada',	'indfall',	'tipodom',	'cod_prov',	'nomprov',	'ind_actividad_cliente',	'renta',	'segmento',	'ind_ahor_fin_ult1',	'ind_aval_fin_ult1',	'ind_cco_fin_ult1',	'ind_cder_fin_ult1',	'ind_cno_fin_ult1',	'ind_ctju_fin_ult1',	'ind_ctma_fin_ult1',	'ind_ctop_fin_ult1',	'ind_ctpp_fin_ult1',	'ind_deco_fin_ult1',	'ind_deme_fin_ult1',	'ind_dela_fin_ult1',	'ind_ecue_fin_ult1',	'ind_fond_fin_ult1',	'ind_hip_fin_ult1',	'ind_plan_fin_ult1',	'ind_pres_fin_ult1',	'ind_reca_fin_ult1',	'ind_tjcr_fin_ult1',	'ind_valo_fin_ult1',	'ind_viv_fin_ult1',	'ind_nomina_ult1',	'ind_nom_pens_ult1',	'ind_recibo_ult1')# NUMBER OF DIFFERENT VALUES IN EACH FEATURE COLUMN:# ===================================================# 17     fecha_dato# 949614 ncodpers# 5      ind_empleado# 118    pais_residencia# 3      sexo# 120    age# 6756   fecha_alta# 2      ind_nuevo# 258    antiguedad# 2      indrel# 224    ult_fec_cli_1t# 10     indrel_1mes# 6      tiprel_1mes# 2      indresi# 2      indext# 3      conyuemp# 163    canal_entrada# 2      indfall# 2      tipodom# 53     cod_prov# 53     nomprov# 2      ind_actividad_cliente# 520995 renta# 4      segmento# 2      ind_ahor_fin_ult1# 2      ind_aval_fin_ult1# 2      ind_cco_fin_ult1# 2      ind_cder_fin_ult1# 2      ind_cno_fin_ult1# 2      ind_ctju_fin_ult1# 2      ind_ctma_fin_ult1# 2      ind_ctop_fin_ult1# 2      ind_ctpp_fin_ult1# 2      ind_deco_fin_ult1# 2      ind_deme_fin_ult1# 2      ind_dela_fin_ult1# 2      ind_ecue_fin_ult1# 2      ind_fond_fin_ult1# 2      ind_hip_fin_ult1# 2      ind_plan_fin_ult1# 2      ind_pres_fin_ult1# 2      ind_reca_fin_ult1# 2      ind_tjcr_fin_ult1# 2      ind_valo_fin_ult1# 2      ind_viv_fin_ult1# 3      ind_nomina_ult1# 3      ind_nom_pens_ult1# 2      ind_recibo_ult1STAT_COLS_0 = COLS_0[1:24]PROD_COLS_0 = COLS_0[-(1:24)]# Categorical columns# Cols that we wish to split into binary cols# Excludes throw-aways like 'tipodom'CATEGORICAL_COLS_0 = c(	# 'ncodpers', # 969614	'ind_empleado', # 5	'pais_residencia', # 119	'sexo', # 3	'ind_nuevo', # 2	'indrel', # 2	'indrel_1mes', # 10	'tiprel_1mes', # 6	'indresi', # 2	'indext', # 2	'conyuemp', # 3	'canal_entrada', # 163	'indfall', # 2	# 'tipodom', # 2	'cod_prov', # 53	# 'nomprov', # 53	'ind_actividad_cliente', # 2	'segmento' # 4)# Real-valued or integer-valued columns (ordinal)# Non-categorical, non-date columnsREAL_COLS_0 = c('age', 'antiguedad', 'renta')DATE_COLS_0 = c('fecha_dato', 'fecha_alta')OMIT_COLS_O = setdiff(setdiff(setdiff(STAT_COLS_0, CATEGORICAL_COLS_0), REAL_COLS_0), DATE_COLS_0)###clean the data: fix dummy variables, fix NA in renta###train_noNA$cod_prov = as.factor(train_noNA$cod_prov)renta_NA_index = which(is.na(train_noNA$renta)) renta_NA = train_noNA[renta_NA_index, ]summary(renta_NA$cod_prov) #65649 NA#sometimes the NA in renta incluldes all the codes of this type. sd is also big wrt mean -- biasget_average_renta = function(i){  rentai_index = which(train_noNA$cod_prov == i)  rentai = train_noNA[rentai_index, ]  mean(rentai$renta, na.rm = TRUE)}average_rentas = sapply(1:52, get_average_renta)#[1] 111098.15  83064.85  87357.52  85400.89  76853.64  72179.26 171996.71 164679.73  97881.71  75365.84  98639.45#[12]  79182.40  69888.34  85610.10 112801.43  69963.82 144280.06  96550.11  95555.57 141895.86  76679.98  89228.52#[23]  77142.96  93382.59  81211.49  99658.08  76686.76 178898.53 121216.29  79084.93 102476.18  83307.51 101403.75#[34]  92760.76 100331.56 113531.58 105810.99 102752.47 121201.13  98463.74 117427.37  88064.11 104581.80  87655.78#[45]  80624.42  89799.89 101653.25 110388.48  83322.11 110587.38 199074.74 149910.16removecolumns = c("sexo_V", "ind_nuevo_1", "indrel_99", "indfall_S", "ind_actividad_cliente_0", "indresi_N", "indext_S", "conyuemp_S")index = which(names(D) %in% removecolumns)D = D[, -index]names(D)[129] = "sexo"names(D)[131] = "ind_nuevo"names(D)[132] = "indrel"names(D)[149] = "indresi"names(D)[150] = "indext"  names(D)[152] = "conyuemp"names(D)[316] = "indfall"names(D)[370] = "ind_actividad_cliente"D$indrel_1mes_1 = D$indrel_1mes_1 + D$indrel_1mes_1.0D$indrel_1mes_2 = D$indrel_1mes_2 + D$indrel_1mes_2.0D$indrel_1mes_3 = D$indrel_1mes_3 + D$indrel_1mes_3.0D$indrel_1mes_4 = D$indrel_1mes_4 + D$indrel_1mes_4.0rmv = c("indrel_1mes_1.0", "indrel_1mes_2.0", "indrel_1mes_3.0", "indrel_1mes_4.0")index2 = which(names(D) %in% rmv)D = D[, -index2]rentas = c(111098.15, 83064.85, 87357.52, 85400.89, 76853.64, 72179.26, 171996.71, 164679.73, 97881.71, 75365.84, 98639.45, 79182.40, 69888.34, 85610.10, 112801.43,  69963.82, 144280.06,  96550.11, 95555.57, 141895.86, 76679.98, 89228.52, 77142.96, 93382.59, 81211.49, 99658.08, 76686.76, 178898.53, 121216.29,  79084.93, 102476.18,  83307.51, 101403.75, 92760.76, 100331.56, 113531.58, 105810.99, 102752.47, 121201.13,  98463.74, 117427.37,  88064.11, 104581.80, 87655.78, 80624.42,  89799.89, 101653.25, 110388.48, 83322.11, 110587.38, 199074.74, 149910.16)prov_cod = train_noNA$cod_provrenta_D = D$rentasummary(renta_D)#Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's #1203    68710   101800   134300   156000 28890000  2766641 for (i in 1:52){  rentai_index = intersect(which(prov_cod == i), which(is.na(renta_D)))  renta_D[rentai_index] = rep(rentas[i], length(rentai_index))}summary(renta_D)#Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's #1203    75370   104900   131700   158200 28890000    65649 #others replace by mediannew_NA_index = which(is.na(renta_D))renta_D[new_NA_index] = median(renta_D, na.rm = TRUE)D$renta = renta_Dsave(D, file = "D_fixbinary_fixrenta.Rda")### Create purchase history variables (Python code) ###import numpy as npimport pandas as pddf  = pd.read_csv("train_ver2.csv",dtype={"sexo":str, "ind_nuevo":str,"ult_fec_cli_1t":str,"indext":str})df =  df[['fecha_dato','ncodpers','ind_ahor_fin_ult1','ind_aval_fin_ult1','ind_cco_fin_ult1','ind_cder_fin_ult1','ind_cno_fin_ult1','ind_ctju_fin_ult1','ind_ctma_fin_ult1','ind_ctop_fin_ult1','ind_ctpp_fin_ult1','ind_deco_fin_ult1','ind_deme_fin_ult1','ind_dela_fin_ult1','ind_ecue_fin_ult1','ind_fond_fin_ult1','ind_hip_fin_ult1','ind_plan_fin_ult1','ind_pres_fin_ult1','ind_reca_fin_ult1','ind_tjcr_fin_ult1','ind_valo_fin_ult1','ind_viv_fin_ult1','ind_nomina_ult1','ind_nom_pens_ult1','ind_recibo_ult1']]df.loc[df.ind_nomina_ult1.isnull(),"ind_nomina_ult1"] = 0df.loc[df.ind_nom_pens_ult1.isnull(),"ind_nom_pens_ult1"] = 0A = [625457,627394, 629209,630367,631957,632110,829817,843201,865440,892251,906109,912021,916269,920904,925076,928274,931453]last = 0current = 0for i in range(17):	if i == 0:		H = df[0:A[i]]	else:		last = last + A[i-1]		current = last + A[i]		temp = df[0:current]		temp = temp.drop('fecha_dato',1).groupby(['ncodpers']).sum()		temp['ncodpers'] = temp.index		temp2 = df[last:current]		temp2 = temp2[['fecha_dato','ncodpers']]		temp2 = pd.merge(left=temp2,right=temp, how='left', left_on='ncodpers', right_on='ncodpers')		print(temp2.shape)		frames = [result,temp2]		H = pd.concat(frames)H.to_csv("H.csv")### ./code/split.r ###to_date <- function (num) {	EPOCH = '1970-01-01';	return(as.POSIXct(num, EPOCH));}if (!exists('D', mode='list'))	D <- read.csv('train.csv');# Get customer ids & reverse indexcids = unique(D$ncodpers); # length is       956645 inv_cids = vector(mode='numeric'); # max is 1553689for (i in 1:length(cids)) {	cid = cids[i];	inv_cids[cid] = i;}print('defined cids and inv_cids');# Vector of dates, where index corresponds to index of cidsmonths = vector(mode='list');# How many CONTIGUOUS months does a each customer have?counts = rep(0, length(cids));# Iterate train.csv entriesfor (i in 1:nrow(D)) {	cid = D$ncodpers[i];	mo  = to_date(D$fecha_dato[i]);	idx = inv_cids[cid];	if (is.na(idx)) stop('no index for cid in inv_cids: ', cid);	if (length(months) < idx || is.null(months[[idx]]))                months[[idx]] = vector(mode='numeric');        months[[idx]] = append(mo, months[[idx]]);	if (0 == i %% 10000) cat(sprintf('\titerated D row %d\n', i));}print('populated "months"');save.image('Split.RData');if (length(months) != length(cids))	stop('mismatch len months vs cids: ', length(months), ':', length(cids));if (sum(is.na(months)))	stop('NA in months');if (sum(is.na(cids)))	stop('NA in cids');# Count contiguous months for each customerfor (row_i in 1:length(months)) {	mos = sort(months[row_i]);	# Ensure there are no gaps in months	if (length(mos) > 1) {		for (i in 2:length(mos)) {			delta = to_date(mos[i]) - to_date(mos[i-1]);			if (abs(30 - delta) > 2)				stop('Gap in month data for cid ', cid, ' ', str(mos));		}	}	counts[row_i] = length(mos);}save.image('Split.RData');df = data.frame(cids, counts);save.image('Split.RData');### ./tmp/logreg.r ###update <- function (x, y, w, lambda) {  err = y - sigmoid(w %*% x) + lambda * w %*% w  gra = err * x  a = 0.1    repeat {    w1 = w + a * gra    err1 = y - sigmoid(w1 %*% x) + lambda * w1 %*% w1    if (err1 < err) break    a = a / 2  }  return(w1)}main <- function (X, Y, lambda) {  X = X[,-c(1,2)]  w = rep(0, length(Y))  for (i in 100000) {    row = sample.int(length(Y), 1)    x = X[row,]    y = Y[row]        w = update(x, y, w, lambda)  }}main <- function (X, Y, lambda) {  X = X[,-c(1,2)]  w = rep(0, length(Y))  for (i in 100000) {    order = sample.int(length(Y), length(Y)    errors = c()    for (row in order) {            x = X[row,]      y = Y[row]                  err = y - sigmoid(w %*% x) + lambda * w %*% w      gra = err * x      a = 0.1        if (err < 0.00001) next            for (i in 1:100) {        w1 = w + a * gra        err1 = y - sigmoid(w1 %*% x) + lambda * w1 %*% w1        if (err1 < err) {          w = w1          break        }        a = a / 2      }      if (100 == i) {        warning('i == 100; didn\'t get good error')      }      errors(end) <- err1    } % end of epoch    if (sum(errors^2) < 0.0001)      return(w)  }}### ./tmp/reg.r ###set.seed(393) # err repeaterset.seed(16)load('Xhead.rda')load('Yhead.rda')X = X[,-c(1,2)]# for (col in 1:length(X))#   X[,col] <- as.numeric(X[,col])X[is.na(X)] <- 0Y = Y[,-c(1,2)]for (col in 1:length(Y))  Y[,col] <- as.numeric(X[,col])Y = Y[, 5]samplect = length(Y)testRows = sample.int(samplect, round(samplect * .2))lambda = 0.1train <- function (X, Y, lambda) {  MSE_THRESHOLD = 0.000001  Y = as.numeric(Y)  m = length(Y) # numer of samples  n = 1 + length(X) # number of features, including bias  w = rep(0, n)  epocherrors = rep(0, m)  prevmserrs = rep(0, 4)  for (epoch in 1:1000) {    order = sample.int(m, m)    for (row in order) {      x = c(1, as.numeric(X[row,]))      y = Y[row]      err0 = y - 1/(1 + exp(w %*% x)) + lambda * w %*% w      gra = err0 * x      a = 0.1      sqerr0 = err0^2      if (sqerr0 < MSE_THRESHOLD) {        epocherrors[row] <- sqerr0        next      }            # Search for a that yields error less than 'err'      for (i in 1:100) {        w1 = w + a * gra        err1 = y - 1/(1 + exp(w1 %*% x)) + lambda * w1 %*% w1        sqerr1 = err1^2        if (sqerr1 <= sqerr0) {          w = w1          break        }        a = a / 2      }      if (100 == i) warning(sprintf('i == 100; didn\'t get good error. epoch %d\t%f vs %f', epoch, err1, err))      # Save error for calculating mse across samples      epocherrors[row] <- sqerr1      if (any(is.na(epocherrors))) {        stop('na err')      }    } # end of epoch    # Calc current error    mserr = epocherrors[row] / m    print(sprintf('epoch %3d    error %f', epoch, mserr))    # Check satisfaction conditions    if (mserr < MSE_THRESHOLD)      return(w)    if (epoch > length(prevmserrs) && all(prevmserrs == mserr))      return(w)    prevmserrs[1 + epoch %% length(prevmserrs)] = mserr  }  warning(sprintf('performed max epochs (%d) on regression', epoch))  return (w)}test <- function (X, Y, w) {  X     = cbind(rep(1, nrow(X)), X)  h     = 1/(1 + exp( X %*% w ))  errs  = h - Y  mserr = mean(errs^2)  print(mserr)}w = train(X[-testRows,], Y[-testRows], lambda)Xt = data.matrix(X[testRows,])Yt = Y[testRows]test(Xt, Yt, w)### ./etl/infer_renta.r ###if (!exists('D') || typeof('D') != 'list') {	load('D_no_cats.rda')	source('constants.r')}predIs   = which(is.na(D$renta))omitcols = union(OMIT_COLS_O, c('D.ncodpers', 'ncodpers', 'fecha_dato'))selcols  = setdiff(names(D), omitcols)xcols    = setdiff(selcols, c('renta'))Dminus   = D[, selcols]DY       = D$rentaarr      = c()rm(D)for (feature in names(Dminus)) {	arr <- c(arr, Dminus[, feature])	Dminus[, feature] <- NULL	print(feature)}save(arr, file='arr.rda')DX = matrix(data=arr, nrow=nrow(Dminus), ncol=length(Dminus))save(DX, file='DX.rda')labeledY = DY[-predIs]labeledX = DX[-predIs, ]labeledN = nrow(labeledX)# Train linear regressiontrainIs = sample.int(labeledN, size=round(labeledN*.9))Y = labeledY[trainIs]X = labeledX[trainIs, ]w = solve(t(X) %*% X) %*% t(X) %*% Y;# Test linear regressionY = labeledY[-trainIs]X = labeledX[-trainIs, ]predictions = t(w) %*% Xrss = sum((Y - predictions)^2) / length(Y)cat('RSS ', rss, '\n')cat('mean', mean(DY, na.rm=TRUE), '\n')cat('stdv', sd(DY, na.rm=TRUE), '\n')# Predict valuesX = DX[predIs, ]predictions = t(w) %*% Xsave(predictions, predIs, file="renta_predictions.rda")### ./etl/pca.r #### Perform PCA to reduce features### ./etl/categories_to_binaries.r #### Turn dates into POSIX dates.# Turn categorical features into multiple binary features.# Exclude features in OMIT_COLS_O.## For this script, you should:## 	load('D_minus_rows.rda')# 	source('../constants.r')# Start with customer identifier colncodpers = D$ncodpersx = data.frame(ncodpers)# Add date colsfor (feature in DATE_COLS_0) {	x[[feature]] = as.POSIXct(D[[feature]])}# Add keeper real stat colsfor (feature in REAL_COLS_0) {	x[[feature]] = D[[feature]]}# Add keeper cat stat colsfor (feature in CATEGORICAL_COLS_0) {	for (value in unique(D[[feature]])) {		new_col_name = sprintf('%s_%s', feature, value)		values = as.numeric(D[[feature]] == value) # make column of {0,1}		x[[new_col_name]] = values	}}# Add all prod colsfor (feature in PROD_COLS_0) {	x[[feature]] = D[[feature]]}D = xsave(D, file='D_no_cats.rda')# 1002.673 sec elapsed (on hpc1)### ./etl/inspect_blanks.r ###load('D.rda') # object containing all of train_ver2.csvblanks.ind_empleado          = grep('^\\s*$', d$ind_empleado)blanks.pais_residencia       = grep('^\\s*$', d$pais_residencia)blanks.fecha_alta            = grep('^\\s*$', d$fecha_alta)blanks.ind_nuevo             = grep('^\\s*$', d$ind_nuevo)blanks.indrel                = grep('^\\s*$', d$indrel)blanks.indresi               = grep('^\\s*$', d$indresi)blanks.indext                = grep('^\\s*$', d$indext)blanks.indfall               = grep('^\\s*$', d$indfall)blanks.ind_actividad_cliente = grep('^\\s*$', d$ind_actividad_cliente)print(sprintf('%d test %s', all(blanks.ind_empleado == blanks.pais_residencia), 'pais_residencia'))print(sprintf('%d test %s', all(blanks.ind_empleado == blanks.fecha_alta), 'fecha_alta'))print(sprintf('%d test %s', all(blanks.ind_empleado == blanks.ind_nuevo), 'ind_nuevo'))print(sprintf('%d test %s', all(blanks.ind_empleado == blanks.indrel), 'indrel'))print(sprintf('%d test %s', all(blanks.ind_empleado == blanks.indresi), 'indresi'))print(sprintf('%d test %s', all(blanks.ind_empleado == blanks.indext), 'indext'))print(sprintf('%d test %s', all(blanks.ind_empleado == blanks.indfall), 'indfall'))print(sprintf('%d test %s', all(blanks.ind_empleado == blanks.ind_actividad_cliente), 'ind_actividad_cliente'))if (!all(blanks.ind_empleado == blanks.pais_residencia))    stop('mismatch 1')if (!all(blanks.ind_empleado == blanks.fecha_alta))    stop('mismatch 2')if (!all(blanks.ind_empleado == blanks.ind_nuevo))    stop('mismatch 3')if (!all(blanks.ind_empleado == blanks.indrel))    stop('mismatch 4')if (!all(blanks.ind_empleado == blanks.indresi))    stop('mismatch 5')if (!all(blanks.ind_empleado == blanks.indext))    stop('mismatch 6')if (!all(blanks.ind_empleado == blanks.indfall))    stop('mismatch 7')if (!all(blanks.ind_empleado == blanks.ind_actividad_cliente))    stop('mismatch 8')# shorter_d = d[-blanks.ind_empleado,]# It appears that all of the 9 columns which have exactly 27334 missing values# are missing values on exactly the same rows, so I expect that it would be# worthwhile to omit those rows.